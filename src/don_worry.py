import operator
import os
from typing import Annotated, Optional

from pydantic import BaseModel, Field
from common.llm_factory import LLMFactory
from common.dataload.pdf_loader import PlanDataLoader
import gradio as gr

from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œí•¨ (íŒŒì¼ì´ ì—†ì–´ë„ ì—ëŸ¬ ë°œìƒí•˜ì§€ ì•ŠìŒ)
load_dotenv()


def setup_environment():
    """í™˜ê²½ë³€ìˆ˜ ì„¤ì • í™•ì¸ ë° ê¸°ë³¸ê°’ ì„¤ì •"""
    # ê¸°ë³¸ PDF ë””ë ‰í† ë¦¬ ì„¤ì •
    country_pdf_dir = os.getenv("COUNTRY_PLAN_PDF_DIR", "raw_files/country_docs")
    city_pdf_dir = os.getenv("CITY_PLAN_PDF_DIR", "raw_files/city_docs")
    reset_db = os.getenv("RESET_DB", "false").lower() == "true"
    
    # ì²˜ë¦¬ ëª¨ë“œ ì„¤ì • (fast: pypdf ìš°ì„ , normal: docling ìš°ì„ )
    process_mode = os.getenv("PDF_PROCESS_MODE", "fast").lower()
    
    # ì„ë² ë”© ëª¨ë¸ ì„¤ì •
    embedding_model = os.getenv("EMBEDDING_MODEL", "bge-m3")
    
    print("ğŸ”§ í™˜ê²½ ì„¤ì •:")
    print(f"  - êµ­í† ê³„íš PDF ë””ë ‰í† ë¦¬: {country_pdf_dir}")
    print(f"  - ì‹œë„êµ° PDF ë””ë ‰í† ë¦¬: {city_pdf_dir}")
    print(f"  - DB ë¦¬ì…‹: {reset_db}")
    print(f"  - ì²˜ë¦¬ ëª¨ë“œ: {process_mode} ({'pypdf ìš°ì„ ' if process_mode == 'fast' else 'docling ìš°ì„ '})")
    print(f"  - ì„ë² ë”© ëª¨ë¸: {embedding_model}")
    
    return country_pdf_dir, city_pdf_dir, reset_db, process_mode, embedding_model


def check_ollama_connection():
    """Ollama ì—°ê²° í™•ì¸"""
    try:
        ollama_url = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")
        print(f"ğŸ¤– Ollama ì—°ê²° í™•ì¸ ì¤‘... ({ollama_url})")
        # ì‹¤ì œ ì—°ê²° í…ŒìŠ¤íŠ¸ëŠ” ì„ë² ë”© ëª¨ë¸ ìƒì„±í•  ë•Œ í™•ì¸ë¨
        return True
    except Exception as e:
        print(f"âš ï¸  Ollama ì—°ê²° ì‹¤íŒ¨: {e}")
        print("   Ollamaê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”: ollama serve")
        return False


def reload_db(need_reset: bool = False, country_pdf_dir: str = "", city_pdf_dir: str = "", embedding_model: str = "bge-m3", process_mode: str = "fast"):
    """ë°ì´í„°ë² ì´ìŠ¤ ë¦¬ë¡œë“œ"""
    if not need_reset:
        print("ğŸ”„ DB ë¦¬ì…‹ì´ ì„¤ì •ë˜ì§€ ì•ŠìŒ. ê¸°ì¡´ ë°ì´í„° ìœ ì§€.")
        return
    
    print("..DB ì¬êµ¬ì¶• ì¤‘..")
    PlanDataLoader.reset_chroma_db()
    
    # PDF ë°ì´í„° ë¡œë” ì´ˆê¸°í™”
    use_docling = (process_mode == "normal")
    pdf_loader = PlanDataLoader(
        embedding_model=embedding_model,
        use_docling=use_docling
    )
    
    # êµ­í† ì¢…í•©ê³„íš íŒŒì¼ ì²˜ë¦¬
    if country_pdf_dir and os.path.exists(country_pdf_dir):
        print(f"\nğŸ“„ êµ­í† ì¢…í•©ê³„íš PDF ì²˜ë¦¬ ì‹œì‘")
        print(f"   ë””ë ‰í† ë¦¬: {country_pdf_dir}")
        
        try:
            country_result = pdf_loader.load_pdf_directory(
                pdf_dir=country_pdf_dir,
                chroma_collection="country_plan",
                embedding_model=embedding_model,
                is_city_file=False,
                chunk_size=1000,
                chunk_overlap=20
            )
            print(f"âœ… êµ­í† ì¢…í•©ê³„íš ì²˜ë¦¬ ê²°ê³¼:")
            print(f"   ì„±ê³µ: {country_result['success_count']}, ì‹¤íŒ¨: {country_result['fail_count']}")
            print(f"   ì´ ì²­í¬: {country_result['total_chunks']}")
            if country_result['failed_files']:
                print("   ì‹¤íŒ¨í•œ íŒŒì¼ë“¤:")
                for failed in country_result['failed_files']:
                    print(f"     - {failed['file']}: {failed['error']}")
        except Exception as e:
            print(f"âŒ êµ­í† ì¢…í•©ê³„íš ì²˜ë¦¬ ì¤‘ ì „ì²´ ì˜¤ë¥˜: {e}")
    else:
        print(f"âš ï¸  êµ­í† ì¢…í•©ê³„íš ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {country_pdf_dir}")
    
    # ì‹œë„êµ° ê¸°ë³¸ê³„íš íŒŒì¼ ì²˜ë¦¬
    if city_pdf_dir and os.path.exists(city_pdf_dir):
        print(f"\nğŸ™ï¸  ì‹œë„êµ° ê¸°ë³¸ê³„íš PDF ì²˜ë¦¬ ì‹œì‘")
        print(f"   ë””ë ‰í† ë¦¬: {city_pdf_dir}")
        
        try:
            city_result = pdf_loader.load_pdf_directory(
                pdf_dir=city_pdf_dir,
                chroma_collection="city_plan",
                embedding_model=embedding_model,
                is_city_file=True,
                chunk_size=1000,
                chunk_overlap=20
            )
            print(f"âœ… ì‹œë„êµ° ê¸°ë³¸ê³„íš ì²˜ë¦¬ ê²°ê³¼:")
            print(f"   ì„±ê³µ: {city_result['success_count']}, ì‹¤íŒ¨: {city_result['fail_count']}")
            print(f"   ì´ ì²­í¬: {city_result['total_chunks']}")
            if city_result['failed_files']:
                print("   ì‹¤íŒ¨í•œ íŒŒì¼ë“¤:")
                for failed in city_result['failed_files']:
                    print(f"     - {failed['file']}: {failed['error']}")
        except Exception as e:
            print(f"âŒ ì‹œë„êµ° ê¸°ë³¸ê³„íš ì²˜ë¦¬ ì¤‘ ì „ì²´ ì˜¤ë¥˜: {e}")
    else:
        print(f"âš ï¸  ì‹œë„êµ° ê¸°ë³¸ê³„íš ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {city_pdf_dir}")


def test_query(query: str, collection_name: str = "country_plan", n_results: int = 5, embedding_model: str = "bge-m3", where: Optional[dict] = None):
    """ì»¬ë ‰ì…˜ì—ì„œ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸"""
    print(f"\nğŸ” ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸: '{query}'")
    print(f"   ì»¬ë ‰ì…˜: {collection_name}")
    print(f"   ì„ë² ë”© ëª¨ë¸: {embedding_model}")
    print(f"   í•„í„°: {where}")
    
    try:
        collection = PlanDataLoader.get_chroma_collection(collection_name)
        if collection is None:
            print(f"âŒ ì»¬ë ‰ì…˜ '{collection_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ì¿¼ë¦¬ìš© ì„ë² ë”© ëª¨ë¸ ìƒì„±
        try:
            embed_model = LLMFactory.create_embedding_model(embedding_model)
        except Exception as e:
            print(f"ì„ë² ë”© ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")
            # ollama bge-m3 ëª¨ë¸ë¡œ fallback
            print("ollama bge-m3 ëª¨ë¸ë¡œ fallback ì‹œë„...")
            embed_model = LLMFactory.create_embedding_model("bge-m3", provider="ollama")
        
        # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
        query_embedding = embed_model.embed_documents([query])[0]
        
        # ì»¬ë ‰ì…˜ì—ì„œ ê²€ìƒ‰ (where í•„í„° ì ìš©)
        query_params = {
            "query_embeddings": [query_embedding],
            "n_results": n_results
        }
        
        #### ìŒ... ì§€ì •í•˜ë©´ ë‚œë¦¬ ë‚˜ë„¤..
        if where:
            query_params["where"] = where
            
        results = collection.query(**query_params)
        
        # ê²°ê³¼ ì•ˆì „ì„± í™•ì¸
        ids = results.get('ids', [[]])
        distances = results.get('distances', [[]])
        documents = results.get('documents', [[]])
        metadatas = results.get('metadatas', [[]])
        
        if ids and len(ids) > 0 and ids[0]:
            result_count = len(ids[0])
            print(f"\nğŸ“Š ê²€ìƒ‰ ê²°ê³¼ ({result_count}ê°œ):")
            
            for i, (doc_id, distance, document, metadata) in enumerate(zip(
                ids[0],
                distances[0] if distances and len(distances) > 0 else [0] * result_count,
                documents[0] if documents and len(documents) > 0 else [''] * result_count,
                metadatas[0] if metadatas and len(metadatas) > 0 else [{}] * result_count
            )):
                print(f"\n{i+1}. ë¬¸ì„œ ID: {doc_id}")
                print(f"   ìœ ì‚¬ë„: {1-distance:.3f}")
                print(f"   ë©”íƒ€ë°ì´í„°: {metadata}")
                print(f"   ë‚´ìš© (ì²˜ìŒ 200ì): {document[:200]}...")
                
                if where:
                    print(f"metadata.get('city_name'): {metadata.get('city_name')} , where.get('city_name'): {where.get('city_name')}")
                    print(f"í™˜ì¥íŒŒí‹°... í•„í„° ì¼ì¹˜: {'âœ…' if metadata.get('city_name') == where.get('city_name') else 'âŒ'} (ê²€ìƒ‰:{where.get('city_name')}, ë¬¸ì„œ:{metadata.get('city_name')})")
                    
            
        else:
            print("   ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        print(f"âŒ ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")


def show_db_status():
    """ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ í‘œì‹œ"""
    print("\n=== ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ: ===")
    try:
        collections = PlanDataLoader.list_collections()
        if not collections:
            print("   ìƒì„±ëœ ì»¬ë ‰ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            for collection in collections:
                info = PlanDataLoader.get_collection_info(collection.name)
                if 'error' not in info:
                    print(f"\nğŸ“‹ ì»¬ë ‰ì…˜: {info['name']}")
                    print(f"   ë¬¸ì„œ ìˆ˜: {info['count']}ê°œ")
                    if info['sample_metadatas']:
                        print(f"   ìƒ˜í”Œ ë©”íƒ€ë°ì´í„°: {info['sample_metadatas'][0]}")
    except Exception as e:
        print(f"   ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")


# main í•¨ìˆ˜ ì •ì˜
def main():
    # í™˜ê²½ ì„¤ì •
    country_pdf_dir, city_pdf_dir, need_reset_db, process_mode, embedding_model = setup_environment()
    
    # Ollama ì—°ê²° í™•ì¸ (bge-m3 ëª¨ë¸ ì‚¬ìš© ì‹œì—ë§Œ)
    if embedding_model == "bge-m3":
        if not check_ollama_connection():
            return
    
    # ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ í™•ì¸
    show_db_status()
    
    # ë°ì´í„°ë² ì´ìŠ¤ ë¦¬ë¡œë“œ (í•„ìš”ì‹œ)
    reload_db(need_reset_db, country_pdf_dir, city_pdf_dir, embedding_model, process_mode)    
    
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì‹¤í–‰
    print("\n" + "="*50)
    # ì¼ë°˜ í…ìŠ¤íŠ¸ ê²€ìƒ‰
    # test_query("ë¶€ì‚° ê´‘ì—­ì‹œ êµí†µë§ ê³„íš", "country_plan", 5, embedding_model)
    # test_query("ë„ì‹œ ê³„íš", "city_plan", 5, embedding_model)
    
    # # ë„ì‹œëª…ìœ¼ë¡œ ê²€ìƒ‰ 
    # test_query("ë„ë¡œ ê³„íš", "city_plan", 5, embedding_model)
    # test_query("ë„ë¡œ ê³„íš", "city_plan", 5, embedding_model, where={"city_name": "youngwol"})
    # test_query("ë„ë¡œ ê³„íš", "city_plan", 5, embedding_model, where={"city_name": "ì˜ì›”"}) #.. ì•ˆë¼... ë§í• ...
    # test_query("ë„ë¡œ ê³„íš", "city_plan", 5, embedding_model, where={"city_name": {"$eq":"ì˜ì›”"}}) #.. ì•ˆë¼... ë§í• ...
    
    
    ###------- Agent ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    from common.agent.agent_manager import AgentManager
    
    print("\nğŸ¤– Agent ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
    try:
        # AgentManager ìƒì„± - ëª¨ë“  Agentì™€ Toolë“¤ì„ ìë™ìœ¼ë¡œ ì„¤ì •
        agent_manager = AgentManager(
            embedding_model=embedding_model,
            llm_model="gpt-4.1-mini"
        )
        
        # Agent ì •ë³´ ì¶œë ¥
        agent_info = agent_manager.get_agent_info()
        print(f"   ì„ë² ë”© ëª¨ë¸: {agent_info['embedding_model']}")
        print(f"   LLM ëª¨ë¸: {agent_info['llm_model']}")
        print(f"   ìƒì„±ëœ Agentë“¤: {', '.join(agent_info['agents'])}")
        print(f"   Supervisor ìƒíƒœ: {agent_info['supervisor_status']}")
        
        # Supervisor ê·¸ë˜í”„ ì €ì¥
        agent_manager.save_supervisor_graph()
        
        print("âœ… Agent ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!")
        
        # Gradio ì±„íŒ… ì•± ìƒì„± ë° ì‹¤í–‰
        create_gradio_app(agent_manager)
        
    except Exception as e:
        print(f"âŒ Agent ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return

def analyze_messages_for_sources(messages):
    """ë©”ì‹œì§€ì—ì„œ ì§ì ‘ agent ì‚¬ìš©ëŸ‰ ë¶„ì„ (fallback)"""
    agent_counts = {"country_plan": 0, "city_plan": 0, "web_search": 0}
    
    for msg in messages:
        msg_str = str(msg)
        
        # ë©”ì‹œì§€ ì´ë¦„ìœ¼ë¡œ í™•ì¸
        if hasattr(msg, 'name') and msg.name:
            if "country_plan_search_agent" in msg.name:
                agent_counts["country_plan"] += 1
            elif "city_plan_search_agent" in msg.name: 
                agent_counts["city_plan"] += 1
            elif "web_search_agent" in msg.name:
                agent_counts["web_search"] += 1
        
        # ë©”ì‹œì§€ ë‚´ìš©ìœ¼ë¡œë„ í™•ì¸ (ë” ê´‘ë²”ìœ„)
        if "country_plan_search" in msg_str.lower() or "êµ­í† ì¢…í•©ê³„íš" in msg_str:
            agent_counts["country_plan"] += 1
        if "city_plan_search" in msg_str.lower() or ("ì‹œë„êµ°" in msg_str and "ê³„íš" in msg_str):
            agent_counts["city_plan"] += 1  
        if "tavily_search" in msg_str.lower() or "web_search" in msg_str.lower():
            agent_counts["web_search"] += 1
    
    # Agentë³„ ì•„ì´ì½˜ê³¼ ì´ë¦„ ë§¤í•‘
    agent_info = {
        "country_plan": {"icon": "ğŸ›ï¸", "name": "êµ­í† ì¢…í•©ê³„íš ë¶„ì„"},
        "city_plan": {"icon": "ğŸ™ï¸", "name": "ì‹œë„êµ° ê¸°ë³¸ê³„íš ë¶„ì„"},
        "web_search": {"icon": "ğŸŒ", "name": "ì›¹ ê²€ìƒ‰ ì •ë³´"}
    }
    
    sources = []
    for agent_source, count in agent_counts.items():
        if count > 0:
            info = agent_info[agent_source]
            # ì¤‘ë³µ ì¹´ìš´íŠ¸ ë°©ì§€ - ìµœëŒ€ 1ë¡œ ì œí•œ
            final_count = min(count, 3)  # ë„ˆë¬´ ë§ì§€ ì•Šê²Œ ì œí•œ
            sources.append(f"{info['icon']} {info['name']} ({final_count}ê±´)")
    
    return " | ".join(sources) if sources else ""


def extract_answer_with_sources(result):
    """ê²°ê³¼ì—ì„œ ì‚¬ìš©ëœ agentë“¤ì˜ ì¶œì²˜ ì •ë³´ ì¶”ì¶œ (metadata ê¸°ë°˜)"""
    if "source_analysis" not in result:
        return ""
    
    source_analysis = result["source_analysis"]
    
    # Agentë³„ ì•„ì´ì½˜ê³¼ ì´ë¦„ ë§¤í•‘
    agent_info = {
        "country_plan": {"icon": "ğŸ›ï¸", "name": "êµ­í† ì¢…í•©ê³„íš ë¶„ì„"},
        "city_plan": {"icon": "ğŸ™ï¸", "name": "ì‹œë„êµ° ê¸°ë³¸ê³„íš ë¶„ì„"},
        "web_search": {"icon": "ğŸŒ", "name": "ì›¹ ê²€ìƒ‰ ì •ë³´"}
    }
    
    # ì‚¬ìš©ëœ agentë“¤ë§Œ ì¶œì²˜ë¡œ í‘œì‹œ
    sources = []
    for agent_source, count in source_analysis.items():
        if count > 0 and agent_source in agent_info:
            info = agent_info[agent_source]
            sources.append(f"{info['icon']} {info['name']} ({count}ê±´)")
    
    return " | ".join(sources) if sources else ""


def create_gradio_app(agent_manager):
    """Gradio ì±„íŒ… ì•± ìƒì„± ë° ì‹¤í–‰"""
    
    def chat_with_supervisor(message, history):
        """supervisor agentì™€ ì±„íŒ…í•˜ëŠ” í•¨ìˆ˜"""
        try:
            # agent_managerë¥¼ í†µí•´ supervisorì™€ ëŒ€í™”
            result = agent_manager.chat(message)
            
            if "error" in result:
                return f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {result['error']}"
            
            # messagesì—ì„œ ë§ˆì§€ë§‰ ë©”ì‹œì§€ ì¶”ì¶œ
            answer = ""
            if "messages" in result and result["messages"]:
                last_message = result["messages"][-1]
                if hasattr(last_message, 'content'):
                    answer = last_message.content
                else:
                    answer = str(last_message)
            
            if not answer:
                return "ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
            
            # ì¶œì²˜ ì •ë³´ ì¶”ê°€ (ê°„ë‹¨í•œ ë©”ì‹œì§€ ë¶„ì„ ìš°ì„  ì‚¬ìš©)
            sources = analyze_messages_for_sources(result.get("messages", []))
            print(f"ğŸ” Direct message analysis sources: '{sources}'")
            
            # metadata ê¸°ë°˜ ë¶„ì„ë„ ì‹œë„
            if not sources:
                sources = extract_answer_with_sources(result)
                print(f"ğŸ” Metadata-based sources: '{sources}'")
            
            if sources:
                answer += "\n\n---\n**ğŸ“‹ ì°¸ê³  ì •ë³´:**\n" + sources
            
            return answer
            
        except Exception as e:
            return f"âŒ ì±„íŒ… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
    
    # Gradio ChatInterface ìƒì„±
    chat_interface = gr.ChatInterface(
        chat_with_supervisor,
        title="ğŸ˜ï¸ Don-Worry ë¶€ë™ì‚° íˆ¬ì ìƒë‹´ ì±—ë´‡",
        description="""
        **êµ­í† ì¢…í•©ê³„íš & ì‹œë„êµ° ê¸°ë³¸ê³„íš ê¸°ë°˜ ë¶€ë™ì‚° íˆ¬ì ìƒë‹´ ì„œë¹„ìŠ¤**
        
        ğŸ” **ì£¼ìš” ê¸°ëŠ¥:**
        - êµ­í† ì¢…í•©ê³„íš ê²€ìƒ‰ ë° ë¶„ì„
        - ì‹œë„êµ° ê¸°ë³¸ê³„íš ì •ë³´ ì œê³µ (í˜„ì¬ëŠ” ì˜ì›”ì‹œë§Œ ìˆì–´ìš©)
        - ì›¹ ê²€ìƒ‰ì„ í†µí•œ ìµœì‹  ì •ë³´ ìˆ˜ì§‘
        - ì¢…í•©ì ì¸ ë¶€ë™ì‚° íˆ¬ì ê°€ì´ë“œ
        
        ğŸ’¡ **ì§ˆë¬¸ ì˜ˆì‹œ:**
        - "ì˜ì›”ì‹œ ì•„íŒŒíŠ¸ íˆ¬ì ì „ë§ì€ ì–´ë–¤ê°€ìš”?"
        - "ë¶€ì‚° ê°•ì„œêµ¬ ê°œë°œ ê³„íšì´ ìˆë‚˜ìš”?"
        - "2025ë…„ ì´í›„ íˆ¬ìí•˜ê¸° ì¢‹ì€ ì§€ì—­ì€ ì–´ë””ì¸ê°€ìš”?"
        """,
        examples=[
            "ì˜ì›”ì‹œì— ì•„íŒŒíŠ¸ íˆ¬ì ê³„íš ì¤‘ì¸ë° ì „ë§ì´ ì–´ë–¤ê°€ìš”?",
            "ë¶€ì‚° ì§€ì—­ ê°œë°œ ê³„íšê³¼ íˆ¬ì ê¸°íšŒë¥¼ ì•Œë ¤ì£¼ì„¸ìš”",
            "2020ë…„ ë‚´ íˆ¬ì ìœ ë§ ì§€ì—­ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”",
            "ê°•ì›ë„ ì§€ì—­ ë¶€ë™ì‚° ì‹œì¥ ì „ë§ì€ ì–´ë–¤ê°€ìš”?",
            "ì¬ê°œë°œ ì˜ˆì • ì§€ì—­ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”"
        ],
        chatbot=gr.Chatbot(
            height=600,
            show_label=False
        ),
        textbox=gr.Textbox(
            placeholder="ë¶€ë™ì‚° íˆ¬ì ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...",
            container=False,
            scale=7
        )
    )
    
    # Gradio ì‹¤í–‰
    chat_interface.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,  # ê³µê°œ ë§í¬ ìƒì„± ì•ˆí•¨
        show_error=True,
        quiet=False
    )
    
    


if __name__ == "__main__":
    main()
    
    