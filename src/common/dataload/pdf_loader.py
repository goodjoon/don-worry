"""
PDF ë°ì´í„° ë¡œë”©ì„ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤ ëª¨ë“ˆ
"""
import os
import glob
from typing import List, Optional, Dict, Any
from langchain_chroma import Chroma
import numpy as np

from docling.document_converter import DocumentConverter
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document
from chromadb import PersistentClient
from ..llm_factory import LLMFactory

# fallbackì„ ìœ„í•œ pypdf import
try:
    from pypdf import PdfReader
    PYPDF_AVAILABLE = True
except ImportError:
    PYPDF_AVAILABLE = False
    print("pypdfë¥¼ ì„¤ì¹˜í•˜ë©´ ë” ì•ˆì •ì ì¸ PDF ì²˜ë¦¬ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤: pip install pypdf")


class PlanDataLoader:
    """
    PDF íŒŒì¼ë“¤ì„ ë¡œë”©í•˜ì—¬ ë²¡í„°DBì— ì €ì¥ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤
    """
    
    # í´ë˜ìŠ¤ ë ˆë²¨ì—ì„œ DB ê²½ë¡œ ê´€ë¦¬
    DB_PATH = "database/chroma"
    
    def __init__(self, embedding_model: Optional[str] = None, use_docling: bool = True):
        self.default_embedding_model = embedding_model or "bge-m3"  # ollama ëª¨ë¸ë¡œ ë³€ê²½
        self.use_docling = use_docling
        
        # ë°ì´í„°ë² ì´ìŠ¤ ë””ë ‰í† ë¦¬ ìƒì„±
        self._ensure_db_directory()
        
    @staticmethod
    def get_chroma_db(collection_name: str, embedding_model: Optional[str] = None) -> Optional[Chroma] :
        """ì»¬ë ‰ì…˜ ì´ë¦„ìœ¼ë¡œ Chroma ì»¬ë ‰ì…˜ ê°ì²´ ë°˜í™˜
        
        Args:
            collection_name: ì»¬ë ‰ì…˜ ì´ë¦„
            embedding_model: ì„ë² ë”© ëª¨ë¸ëª… (ê¸°ë³¸ê°’: bge-m3)
            
        Returns:
            Collection: Chroma ì»¬ë ‰ì…˜ ê°ì²´. ì»¬ë ‰ì…˜ì´ ì—†ìœ¼ë©´ None ë°˜í™˜
        """
        try:
            # ì„ë² ë”© ëª¨ë¸ ìƒì„±
            embed_model = LLMFactory.create_embedding_model(embedding_model or "bge-m3")
            
            # Chroma ê°ì²´ ìƒì„± ë° ë°˜í™˜
            from langchain_community.vectorstores import Chroma
            return Chroma(
                embedding_function=embed_model,
                collection_name=collection_name,
                persist_directory=PlanDataLoader.DB_PATH
            )
        except Exception as e:
            print(f"Chroma ì»¬ë ‰ì…˜ ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def _ensure_db_directory(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³  ìƒì„±"""
        os.makedirs(self.DB_PATH, exist_ok=True)
        print(f"ğŸ“ Chroma DB ê²½ë¡œ: {os.path.abspath(self.DB_PATH)}")
    
    @classmethod
    def get_chroma_client(cls):
        """Chroma DB í´ë¼ì´ì–¸íŠ¸ ë°˜í™˜"""
        cls._ensure_class_db_directory()
        return PersistentClient(path=cls.DB_PATH)
    
    @classmethod
    def _ensure_class_db_directory(cls):
        """í´ë˜ìŠ¤ ë©”ì„œë“œìš© DB ë””ë ‰í† ë¦¬ í™•ì¸"""
        os.makedirs(cls.DB_PATH, exist_ok=True)
    
    def _extract_text_with_pypdf(self, pdf_path: str) -> str:
        """pypdfë¥¼ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (fallback)"""
        if not PYPDF_AVAILABLE:
            raise ImportError("pypdfê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
        
        reader = PdfReader(pdf_path)
        text = ""
        for page in reader.pages:
            text += page.extract_text() + "\n"
        return text.strip()
    
    def _extract_text_with_docling(self, pdf_path: str) -> str:
        """doclingì„ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ë©”ì¸)"""
        converter = DocumentConverter()
        docling_doc = converter.convert(pdf_path)
        return docling_doc.document.export_to_text()
    
    def load_single_pdf(
        self,
        pdf_path: str,
        chroma_collection: str = "default",
        embedding_model: Optional[str] = None,
        chunk_size: int = 1000,
        chunk_overlap: int = 100,
        additional_metadata: Optional[dict] = None,
        **kwargs
    ) -> int:

        if not os.path.exists(pdf_path):
            raise FileNotFoundError(f"PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {pdf_path}")

        # 1. PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (docling ìš°ì„ , ì‹¤íŒ¨ì‹œ pypdf ì‚¬ìš©)
        text = None
        extraction_method = "unknown"
        
        if self.use_docling:
            try:
                print(f"  doclingìœ¼ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„...")
                text = self._extract_text_with_docling(pdf_path)
                extraction_method = "docling"
                print(f"  docling ì¶”ì¶œ ì„±ê³µ!")
            except Exception as e:
                print(f"  docling ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                if PYPDF_AVAILABLE:
                    try:
                        print(f"  pypdfë¡œ fallback ì‹œë„...")
                        text = self._extract_text_with_pypdf(pdf_path)
                        extraction_method = "pypdf"
                        print(f"  pypdf ì¶”ì¶œ ì„±ê³µ!")
                    except Exception as e2:
                        print(f"  pypdf ì¶”ì¶œë„ ì‹¤íŒ¨: {e2}")
                        raise ValueError(f"ëª¨ë“  PDF ì¶”ì¶œ ë°©ë²•ì´ ì‹¤íŒ¨í•¨. docling: {e}, pypdf: {e2}")
                else:
                    raise ValueError(f"docling ì¶”ì¶œ ì‹¤íŒ¨í•˜ê³  pypdfê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ: {e}")
        else:
            # pypdfë§Œ ì‚¬ìš©
            if PYPDF_AVAILABLE:
                text = self._extract_text_with_pypdf(pdf_path)
                extraction_method = "pypdf"
            else:
                raise ValueError("pypdfê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ê³  docling ì‚¬ìš©ì´ ë¹„í™œì„±í™”ë¨")
        
        if not text or not text.strip():
            raise ValueError("PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í•¨")
        
        # ê¸°ë³¸ ë©”íƒ€ë°ì´í„° ì„¤ì •
        base_metadata = {
            "source": pdf_path,
            "extraction_method": extraction_method
        }
        # ì¶”ê°€ ë©”íƒ€ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë³‘í•©
        if additional_metadata:
            base_metadata.update(additional_metadata)
        
        docs = [Document(page_content=text, metadata=base_metadata)]

        # 2. í…ìŠ¤íŠ¸ ë¶„í• 
        splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)
        split_docs = splitter.split_documents(docs)
        if not split_docs:
            raise ValueError("í…ìŠ¤íŠ¸ ë¶„í•  ê²°ê³¼ê°€ ì—†ìŒ")

        # 3. ì„ë² ë”© ëª¨ë¸ ì¤€ë¹„
        model_name = embedding_model or self.default_embedding_model
        try:
            embed_model = LLMFactory.create_embedding_model(model_name)
        except Exception as e:
            print(f"ì„ë² ë”© ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")
            # ollama bge-m3 ëª¨ë¸ë¡œ fallback
            print("ollama bge-m3 ëª¨ë¸ë¡œ fallback ì‹œë„...")
            embed_model = LLMFactory.create_embedding_model("bge-m3", provider="ollama")

        # 4. Chroma DB ì—°ê²° ë° ì»¬ë ‰ì…˜ ì¤€ë¹„
        chroma_client = self.get_chroma_client()
        
        # ì„ë² ë”© í•¨ìˆ˜ë¥¼ í¬í•¨í•œ ì»¬ë ‰ì…˜ ìƒì„±
        try:
            collection = chroma_client.get_collection(name=chroma_collection)
            print(f"  ê¸°ì¡´ ì»¬ë ‰ì…˜ '{chroma_collection}' ì‚¬ìš©")
        except Exception:
            # ì»¬ë ‰ì…˜ì´ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„± (ì„ë² ë”© í•¨ìˆ˜ ì—†ì´)
            collection = chroma_client.create_collection(name=chroma_collection)
            print(f"  ìƒˆ ì»¬ë ‰ì…˜ '{chroma_collection}' ìƒì„±")

        # 5. ì„ë² ë”© ë° ì €ì¥
        texts = [doc.page_content for doc in split_docs]
        try:
            embeddings = np.array(embed_model.embed_documents(texts), dtype=np.float32)
        except Exception as e:
            print(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            raise
        
        ids = [f"{os.path.basename(pdf_path)}_{i}" for i in range(len(texts))]
        
        # ê° ì²­í¬ì— ë™ì¼í•œ ë©”íƒ€ë°ì´í„° í• ë‹¹
        from typing import cast
        metadatas = cast(list, [doc.metadata for doc in split_docs])
        
        collection.add(
            embeddings=embeddings,
            documents=texts,
            metadatas=metadatas,
            ids=ids
        )
        return len(texts)
    
    def load_pdf_directory(
        self,
        pdf_dir: str,
        chroma_collection: str,
        is_city_file: bool = False,
        embedding_model: Optional[str] = None,
        chunk_size: int = 1000,
        chunk_overlap: int = 100,
        **kwargs
    ) -> Dict[str, Any]:
        result = {
            "success_count": 0,
            "fail_count": 0,
            "total_chunks": 0,
            "processed_files": [],
            "failed_files": []
        }
        
        if not pdf_dir or not os.path.exists(pdf_dir):
            print(f"PDF ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ì„¤ì •ë˜ì§€ ì•ŠìŒ: {pdf_dir}")
            return result
        
        # ë””ë ‰í† ë¦¬ ë‚´ì˜ ëª¨ë“  PDF íŒŒì¼ ì°¾ê¸°
        pdf_files = glob.glob(os.path.join(pdf_dir, "*.pdf"))
        print(f"ë°œê²¬ëœ PDF íŒŒì¼ ìˆ˜: {len(pdf_files)}")
        
        for pdf_file in pdf_files:
            try:
                print(f"ì²˜ë¦¬ ì¤‘: {pdf_file}")
                
                # ë©”íƒ€ë°ì´í„° ì¤€ë¹„
                additional_metadata = None
                city_name = None
                
                if is_city_file:
                    # PDF íŒŒì¼ëª…ì—ì„œ ë„ì‹œëª… ì¶”ì¶œ (íŒŒì¼ëª…ì„ '_'ë¡œ êµ¬ë¶„í–ˆì„ ë•Œ ì²« ë²ˆì§¸ ë‹¨ì–´)
                    pdf_filename = os.path.basename(pdf_file)
                    pdf_name_without_ext = os.path.splitext(pdf_filename)[0]  # í™•ì¥ì ì œê±°
                    city_name = pdf_name_without_ext.split('_')[0]  # '_'ë¡œ êµ¬ë¶„í•œ ì²« ë²ˆì§¸ ë‹¨ì–´
                    additional_metadata = {"city_name": city_name}
                
                # PDF ì²˜ë¦¬ ë° ì €ì¥
                chunk_count = self.load_single_pdf(
                    pdf_path=pdf_file,
                    chroma_collection=chroma_collection,
                    embedding_model=embedding_model,
                    chunk_size=chunk_size,
                    chunk_overlap=chunk_overlap,
                    additional_metadata=additional_metadata,
                    **kwargs
                )
                
                # ê²°ê³¼ ê¸°ë¡
                result["success_count"] += 1
                result["total_chunks"] += chunk_count
                result["processed_files"].append({
                    "file": pdf_file,
                    "chunks": chunk_count,
                    "city_name": city_name if is_city_file else None
                })
                
                if is_city_file:
                    print(f"  ì €ì¥ëœ ì²­í¬ ìˆ˜: {chunk_count}, ë„ì‹œëª…: {city_name}")
                else:
                    print(f"  ì €ì¥ëœ ì²­í¬ ìˆ˜: {chunk_count}")
                    
            except Exception as e:
                print(f"PDF íŒŒì¼ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({pdf_file}): {e}")
                result["fail_count"] += 1
                result["failed_files"].append({"file": pdf_file, "error": str(e)})
                continue
        
        print(f"ì²˜ë¦¬ ì™„ë£Œ - ì„±ê³µ: {result['success_count']}, ì‹¤íŒ¨: {result['fail_count']}, ì´ ì²­í¬: {result['total_chunks']}")
        return result

    @staticmethod
    def get_chroma_collection(collection_name: str):
        """ì§€ì •ëœ ì»¬ë ‰ì…˜ ë°˜í™˜"""
        client = PlanDataLoader.get_chroma_client()
        try:
            return client.get_collection(name=collection_name)
        except Exception as e:
            print(f"ì»¬ë ‰ì…˜ '{collection_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {e}")
            return None

    @staticmethod
    def list_collections():
        """ëª¨ë“  ì»¬ë ‰ì…˜ ëª©ë¡ ë°˜í™˜"""
        client = PlanDataLoader.get_chroma_client()
        collections = client.list_collections()
        print(f"ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ë ‰ì…˜ ({len(collections)}ê°œ):")
        for collection in collections:
            count = collection.count()
            print(f"  - {collection.name}: {count}ê°œ ë¬¸ì„œ")
        return collections
    
    @staticmethod
    def reset_chroma_db(chroma_collection: Optional[str] = None):
        """
        Chroma DB ì´ˆê¸°í™”
        """
        client = PlanDataLoader.get_chroma_client()
        if chroma_collection:
            # ì§€ì •í•œ ì»¬ë ‰ì…˜ë§Œ ì‚­ì œ
            collections = [col.name for col in client.list_collections()]
            if chroma_collection in collections:
                client.delete_collection(name=chroma_collection)
                print(f"ì»¬ë ‰ì…˜ '{chroma_collection}' ì‚­ì œ ì™„ë£Œ")
            else:
                print(f"ì»¬ë ‰ì…˜ '{chroma_collection}'ì´(ê°€) ì¡´ì¬í•˜ì§€ ì•ŠìŒ")
        else:
            # ì „ì²´ ì»¬ë ‰ì…˜ ì‚­ì œ
            collections = client.list_collections()
            for col in collections:
                client.delete_collection(name=col.name)
            print(f"ì „ì²´ ì»¬ë ‰ì…˜ ({len(collections)}ê°œ) ì‚­ì œ ì™„ë£Œ")
    
    @staticmethod
    def get_collection_info(collection_name: str) -> Dict[str, Any]:
        """ì»¬ë ‰ì…˜ ì •ë³´ ë°˜í™˜"""
        try:
            collection = PlanDataLoader.get_chroma_collection(collection_name)
            if collection is None:
                return {"error": f"ì»¬ë ‰ì…˜ '{collection_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ"}
            
            count = collection.count()
            # ìƒ˜í”Œ ë°ì´í„° ëª‡ ê°œ ê°€ì ¸ì˜¤ê¸°
            sample_results = collection.peek(limit=3)
            
            return {
                "name": collection_name,
                "count": count,
                "sample_ids": sample_results.get('ids', []),
                "sample_metadatas": sample_results.get('metadatas', [])
            }
        except Exception as e:
            return {"error": str(e)} 